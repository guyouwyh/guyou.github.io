<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>努力走,走到灯火通明</title>
        <subtitle></subtitle>
        <icon>https://guyouwyh.github.io/guyouwyh/images/favicon.ico</icon>
        <link>https://guyouwyh.github.io/guyouwyh</link>
        <author>
          <name>故犹</name>
        </author>
        <description></description>
        <language>zh-CN</language>
        <pubDate>Tue, 01 Nov 2022 12:10:48 +0800</pubDate>
        <lastBuildDate>Tue, 01 Nov 2022 12:10:48 +0800</lastBuildDate>
        <item>
            <guid isPermalink="true">https://guyouwyh.github.io/guyouwyh/2022/11/01/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/JMM%E5%92%8Cvolatile%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/</guid>
            <title>JMM和volatile的一些理解</title>
            <link>https://guyouwyh.github.io/guyouwyh/2022/11/01/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/JMM%E5%92%8Cvolatile%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/</link>
            <category term="后端" scheme="https://guyouwyh.github.io/guyouwyh/categories/%E5%90%8E%E7%AB%AF/" />
            <category term="Java" scheme="https://guyouwyh.github.io/guyouwyh/categories/%E5%90%8E%E7%AB%AF/Java/" />
            <category term="Java并发" scheme="https://guyouwyh.github.io/guyouwyh/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/" />
            <category term="Java" scheme="https://guyouwyh.github.io/guyouwyh/tags/Java/" />
            <pubDate>Tue, 01 Nov 2022 12:10:48 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;jmm是什么&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#jmm是什么&#34;&gt;#&lt;/a&gt; JMM 是什么？&lt;/h1&gt;
&lt;p&gt;对于学 Java 多线程的人来说，一定听说过 JMM, 那么 JMM 到底是什么呢？JMM 全称 (&lt;ins&gt;Java Memory Model&lt;/ins&gt;) 即 Java 内存模型。它是 Java 的一套规范，对上，是 JVM 和开发者之间的约定，对下，是 JVM 和编译器、CPU 之间的约定。&lt;/p&gt;
&lt;h1 id=&#34;jmm是作用是什么&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#jmm是作用是什么&#34;&gt;#&lt;/a&gt; JMM 是作用是什么？&lt;/h1&gt;
&lt;p&gt;JMM 是作用主要是明确在多线程环境下，什么时候需要重排序，什么时候不需要重排序。为了更好的了解 JMM, 先介绍一下内存的可见性问题和重排序问题。&lt;/p&gt;
&lt;h1 id=&#34;内存可见性问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内存可见性问题&#34;&gt;#&lt;/a&gt; 内存可见性问题&lt;/h1&gt;
&lt;p&gt;首先来说说，为什么会存在内存可见性问题？举个栗子，假设是一个 2 核 CPU, 在 x86 架构下它的缓存布局如下:&lt;br /&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/guyouwyh/picture/main/20221101160705.png&#34; alt=&#34;&#34; /&gt;&lt;br /&gt;
CPU 有 3 级缓存，因为存在 CPU 缓存一致性协议 MESI, 多个 CPU 缓存不会出现不同步问题，因此不会有不可见问题。&lt;br /&gt;
但是还有个问题就是：使用缓存一致性协议，会对性能有很大的损耗，因此 CPU 的设计者们又进行了优化，比如在 CPU 计算单元与 L1 缓存之间又加上了 LoadBuufer 和 StoreBuffer。&lt;br /&gt;
L1、L2、L3 缓存与主存之间，由于有缓存一致性协议的缘故，是同步的，但是 L1 和 StoreBuffer 和 LoadBuffer 之间并不是同步的，通俗来说 ++&amp;quot;往内存中写入一个变量，这个变量会先被写入到 StoreBuffer 中，稍后异步写入 L1 缓存中，同时同步写入主内存中&amp;quot;++。&lt;br /&gt;
基于这个原因，如果我们在引入 StoreBuffer 之后，CPU 读取变量时，直接从缓存中读取，则可能出现 StoreBuffer 中存在已经修改的变量，但是还未同步到缓存中，因此 CPU 会先从 StoreBuffer 中读取，这样保证了单 CPU 顺序执行指令过程的可见性。 这种机制也被称为 Store Fowarding。&lt;/p&gt;
&lt;p&gt;但是，如果我们站在操作系统内核的角度下看 CPU 缓存模型是这样的:&lt;br /&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/guyouwyh/picture/main/20221101162224.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;然后 JVM 就将这种模型抽象成了 JMM 模型:&lt;br /&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/guyouwyh/picture/main/20221101162419.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;重排序&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#重排序&#34;&gt;#&lt;/a&gt; 重排序&lt;/h1&gt;
&lt;p&gt;重排序由三个分类:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;编译器重排序：对于没有先后以来关系的语句，编译器可以重新调整语句的执行顺序&lt;/li&gt;
&lt;li&gt;CPU 指令重排序：在指令级别，让没有以来关系的多条指令并行&lt;/li&gt;
&lt;li&gt;CPU 内存重排序: CPU 有自己的缓存，执行的执行顺序和写入主内存的顺序不完全一致&lt;br /&gt;
一般而言，第三类就是造成内存可见性的主要原因。&lt;br /&gt;
举个例子，如果有两个线程 A 和 B。有一个全局变量 X=0, 如果线程 A 先修改了 X=1, 但是此时，由于要先写入 StoreBuffer, 此时并没有刷新到主内存，主内存中的 X 还是等于 0, 此时线程 B 看到的 X 还是 0。&lt;br /&gt;
将这种重排序称为内存重排序，会造成内存可见性问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果站在开发者的角度来看，肯定是希望不要有任何重排序，这样写内存的顺序也会跟代码顺序一样。&lt;br /&gt;
但是，如果站在 CPU 的角度来看，会尽可能的进行重排序，提升运行效率。&lt;br /&gt;
这时候就产生了一个问题，重排序要有什么原则？要在什么场景下进行重排序？又或者说在什么场景下不能重排序？这相当于是对于开发者和 CPU 之间的一个约定。&lt;/p&gt;
&lt;h2 id=&#34;单线程程序的重排序规则&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#单线程程序的重排序规则&#34;&gt;#&lt;/a&gt; 单线程程序的重排序规则&lt;/h2&gt;
&lt;p&gt;对于单线程程序来说，只要没有产生数据依赖性，也就是操作 B 不依赖于操作 A, 那么 CPU 就可以任意重排序，因为最终产生的结果并不会改变。从开发者的角度来看，这样代码从头执行到尾，这就是 as-if-serial 语义，编译器可和 CPU 或许因为运行效率而做了重排序，但是，开发者感知不到，这样就不会产生内存可见性原因.&lt;/p&gt;
&lt;h2 id=&#34;多线程重排序规则&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#多线程重排序规则&#34;&gt;#&lt;/a&gt; 多线程重排序规则&lt;/h2&gt;
&lt;p&gt;对于多线程来说，编译器和 CPU 只能保证单个线程的 as-if-serial 语义，但是，如果多个线程操作了共享变量，对于这种影响，编译期和 CPU 并不会考虑，也就产生了可见性的问题。那么为了解决在多线程的情况下的重排序问题，也就衍生出来了另外一种规则 ----&lt;span class=&#34;rainbow&#34;&gt;happen-before&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;首先介绍为什么会有 happen-before。&lt;br /&gt;
为了明确定义在多线程场景下，什么时候可以重排序，什么时候不能重排序，Java 引入了 JMM, 这只是一套规范，但是，如何去描述这个规范呢？JMM 就引入了 happen-before, 使用 happen-before 去描述这两个操作之间的内存可见性。&lt;/p&gt;
&lt;p&gt;那么 happen-before 究竟是什么呢？&lt;br /&gt;
顾名思义，happen-before 也就是发生在什么之前，如果 A happen-before B, 那么 B 应该清楚的知道 A 的所作所为，即 A 的执行结果必须对 B 可见，保证了跨线程的内存可见性。&lt;br /&gt;
然而，happen-before 并不代表 A 一定在 B 之前执行，但是如果 A 在 B 之前执行，那么 A 的结果一定对 B 可见，也就是定义了内存可见性的约束。&lt;br /&gt;
JMM 对开发者做出了一系列承诺:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单线程中的每个操作，happen-before 对应线程中任意后续操作，即 as-if-serial 语义保证&lt;/li&gt;
&lt;li&gt;对 volatile 变量的写入，happen-before 对应后续对这个变量的读取&lt;/li&gt;
&lt;li&gt;对 synchronized 的解锁，happen-before 对应后续对这个锁的加锁。&lt;/li&gt;
&lt;li&gt;如果 A happen-before B, B happen-before C , 那么 A happen-before C (即具有传递性)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样也就保证了内存的可见性，但是，在操作系统底层是怎么保证的呢？这就要说说内存屏障了。&lt;/p&gt;
&lt;h1 id=&#34;内存屏障&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内存屏障&#34;&gt;#&lt;/a&gt; 内存屏障&lt;/h1&gt;
&lt;p&gt;为了禁止编译器重排序和 CPU 重排序，在编译器和 CPU 层面都有对应的指令，也就是内存屏障 (Memory Barrier). 这也正是 JMM 和 happen-before 规则的底层实现原理。&lt;/p&gt;
&lt;p&gt;编译器的内存屏障，只是为了告诉编译器不要对指令进行重排序。CPU 并不会感知编译器中内存屏障的存在&lt;/p&gt;
&lt;p&gt;而 CPU 的内存屏障是 CPU 提供的，可以由开发者显式调用。&lt;/p&gt;
&lt;h2 id=&#34;cpu中的内存屏障&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#cpu中的内存屏障&#34;&gt;#&lt;/a&gt; CPU 中的内存屏障&lt;/h2&gt;
&lt;p&gt;在理论层面，可以把基本的 CPU 内存屏障分为 4 种:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;LoadLoad: 禁止读和读重排序&lt;/li&gt;
&lt;li&gt;StoreStore: 禁止写和写的重排序&lt;/li&gt;
&lt;li&gt;LoadStore: 禁止读和写的重排序&lt;/li&gt;
&lt;li&gt;StoreLoad: 禁止写和读的重排序&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;jdk中的内存屏障&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#jdk中的内存屏障&#34;&gt;#&lt;/a&gt; JDK 中的内存屏障&lt;/h2&gt;
&lt;figure class=&#34;highlight java&#34;&gt;&lt;figcaption data-lang=&#34;java&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;native&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;loadFence&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt; &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt; &lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;native&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;storeFence&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt; &lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;native&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;fullFence&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;可以看到，在 Unsafe 类中，提供了三种内存屏障，这三种内存屏障与 CPU 内存屏障的对应关系如下:&lt;br /&gt;
&lt;span class=&#34;blue&#34;&gt;loadFench = LoadLoad+ LoadSotre&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;blue&#34;&gt;storeFench = StoreStore + LoadStore&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;blue&#34;&gt;FullFench  = loadFence + storeFench + StoreLoad&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;内存屏障的应用-volatile&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内存屏障的应用-volatile&#34;&gt;#&lt;/a&gt; 内存屏障的应用 --volatile&lt;/h2&gt;
&lt;p&gt;相信大家都知道 volatile 这个关键字。valtile 有如下作用:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;mark&gt;解决 64 位的写入问题&lt;/mark&gt;&lt;br /&gt;
 JVM 的规范并没有要求 64 位的 long 或者 double 的写入是原子的。在 32 位的机器上，一个 64 位的变量写入可能被拆分成两个 32 位的写操作来执行。这样一来，读取的线程就可能读到一半的值。解决办法是在 long 前面加上 volatile 关键字。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;mark&gt;解决内存可见性问题&lt;/mark&gt;&lt;br /&gt;
使用 volatile 关键字修饰的变量，会立刻从本地内存中刷新到共享内存中，保证了内存的可见性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;mark&gt;解决重排序问题&lt;/mark&gt;&lt;br /&gt;
在使用 DCL, 即双重检查锁的时候，变量需要声明为 volatle, 这里也是为了防止指令重排序。&lt;br /&gt;
当我们 new 一个对象的时候，其实会发生三个步骤:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;在堆中开辟一段空间&lt;/li&gt;
&lt;li&gt;在这段空间 (内存) 上初始化成员变量&lt;/li&gt;
&lt;li&gt;将引用指向这段空间的地址&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果将步骤 2 和步骤 3 重排序了，获取的对象将会是未初始化的对象。这就会造成一些很严重的问题。&lt;/p&gt;
&lt;p&gt;事实上，volatile 关键字底层就是使用了内存屏障。&lt;br /&gt;
&lt;strong&gt;1. 在 volatile 写操作前面插入一个 StoreStore 屏障。保证 volatile 写操作不会和之前的写操作重排序&lt;br /&gt;
 2. 在 volatile 写操作后插入一个 StoreLoad 屏障，保证 volatile 写操作不会和之后的读操作重排序&lt;br /&gt;
 3. 在 volatile 读操作后面插入一个 LoadLoad 屏障和 LoadStore 屏障，保证 volatile 读操作不会和之后的读操作、写操作重排序&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#总结&#34;&gt;#&lt;/a&gt; 总结&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;通俗来说，JMM 其实就是 Java 提供的一种内存模型，每个线程都有自己的本地缓存，所有线程都有一个共享内存，本地缓存中的变量相当于是共享内存中变量的一个副本，当我们修改一个变量的时候，事实上会直接修改本地缓存中的变量，并不会立即刷新到共享内存中，这样就导致了多个线程之间不可见问题。&lt;br /&gt;
如果站在我们开发者的角度来说，可以使用 synchronized、volatile、final 去解决重排序以及可见性问题。&lt;br /&gt;
但是如果站在 JVM 的角度来说，它其实是通过 JMM 的 happen-before 规则来解决的。&lt;br /&gt;
更深层次一点，站在 CPU 层面来说，主要是通过内存屏障来解决的。&lt;/strong&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
